import streamlit as st
import pandas as pd
import numpy as np
import torch
import plotly.graph_objects as go
from tqdm import tqdm

# --- å¯¼å…¥æ¨¡å— (æ— å˜åŒ–) ---
try:
    from dataloader_setup import FinancialDataset
    from VAE_trainer import TransformerVAE_TDist
    from vis import LatentOHLCVPredictor
except ImportError as e:
    st.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}. è¯·ç¡®ä¿ç›¸å…³æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
    st.stop()


# --- æ¨¡å‹ä¸æ•°æ®åŠ è½½å‡½æ•° (æ— å˜åŒ–) ---
@st.cache_resource
def load_vae_model(vae_path, feature_dim, latent_dim, embed_dim, df, device):
    model = TransformerVAE_TDist(feature_dim=feature_dim, latent_dim=latent_dim, embed_dim=embed_dim, df=df).to(device)
    model.load_state_dict(torch.load(vae_path, map_location=device))
    model.eval()
    return model


@st.cache_resource
def load_predictor_model(predictor_path, latent_dim, ohlcv_dim, seq_length, device):
    model = LatentOHLCVPredictor(latent_dim=latent_dim, ohlcv_dim=ohlcv_dim, seq_length=seq_length).to(device)
    model.load_state_dict(torch.load(predictor_path, map_location=device))
    model.eval()
    return model


@st.cache_data
def load_financial_data(_dataset, csv_path, seq_length, latent_dim):
    # _dataset å‚æ•°æ˜¯ä¸ºäº†è®© Streamlit çš„ç¼“å­˜çŸ¥é“æ•°æ®æ–‡ä»¶å·²æ›´æ–°
    dataset = FinancialDataset(latent_csv_path=csv_path, seq_length=seq_length, latent_dim=latent_dim)
    return dataset


# --- æ ¸å¿ƒå›æµ‹é€»è¾‘ï¼šä¿®æ­£ä»·æ ¼è·å–æ–¹å¼ ---
def run_adaptive_backtest(predictor_model, dataset, raw_df, day_start_idx, seq_length,
                          total_quantity, trade_direction, failsafe_ratio, device):
    """
    æ‰§è¡ŒåŠ¨æ€è‡ªé€‚åº”å›æµ‹ç­–ç•¥ã€‚
    **V3ç‰ˆ: ä¿®æ­£äº†ä»·æ ¼é€»è¾‘ï¼Œä½¿ç”¨åŸå§‹HLCå‡ä»·ä½œä¸ºæˆäº¤ä»·ã€‚**
    """
    remaining_quantity = float(total_quantity)
    results_log = []

    for t in tqdm(range(seq_length), desc="Running Adaptive Backtest"):
        order_quantity_for_this_minute = 0.0
        logic_used = ""

        # --- è¾¹ç•Œæ¡ä»¶1: æå‰å®Œæˆ ---
        if remaining_quantity <= 1e-6:
            logic_used = "å·²å®Œæˆ"
            order_quantity_for_this_minute = 0.0
        # --- è¾¹ç•Œæ¡ä»¶2: æ”¶ç›˜å†²åˆº ---
        elif t >= seq_length - 5:
            logic_used = f"æ”¶ç›˜å†²åˆº (r={failsafe_ratio})"
            minutes_left = seq_length - t
            if minutes_left == 1:
                order_quantity_for_this_minute = remaining_quantity
            else:
                if abs(1.0 - failsafe_ratio) < 1e-9:
                    first_term = remaining_quantity / minutes_left
                else:
                    first_term = remaining_quantity * (1 - failsafe_ratio) / (1 - failsafe_ratio ** minutes_left)
                order_quantity_for_this_minute = first_term
        # --- ä¸»è¦é€»è¾‘: æ¨¡å‹é¢„æµ‹ ---
        else:
            logic_used = "æ¨¡å‹é¢„æµ‹"
            input_start_idx = day_start_idx + t - seq_length
            input_end_idx = day_start_idx + t

            if input_start_idx < 0:
                order_quantity_for_this_minute = 0.0
            else:
                input_latent_seq_np = dataset.normalized_latent[input_start_idx:input_end_idx]
                input_tensor = torch.FloatTensor(input_latent_seq_np).unsqueeze(0).to(device)

                with torch.no_grad():
                    outputs = predictor_model(input_tensor)['ohlcv_pred'].squeeze(0).cpu().numpy()
                    preds_scaled_back = dataset.ohlcv_scaler.inverse_transform(outputs)
                    preds_raw = np.expm1(preds_scaled_back)
                    predicted_volumes_future = preds_raw[:, 5]

                    predicted_volume_for_now = predicted_volumes_future[-1]
                    sum_of_future_predicted_volumes = np.sum(predicted_volumes_future)

                    if sum_of_future_predicted_volumes > 1e-6:
                        weight_for_this_minute = predicted_volume_for_now / sum_of_future_predicted_volumes
                        order_quantity_for_this_minute = remaining_quantity * weight_for_this_minute
                    else:
                        minutes_left_in_model_horizon = seq_length - t
                        order_quantity_for_this_minute = remaining_quantity / minutes_left_in_model_horizon

        # --- æ‰§è¡Œä¸è®°å½• ---
        final_order_quantity = max(0.0, min(remaining_quantity, order_quantity_for_this_minute))

        # ã€å…³é”®ä¿®æ­£ã€‘ä»åŸå§‹DataFrameè·å–æœªå¤„ç†çš„ä»·æ ¼å’Œæˆäº¤é‡
        current_minute_raw_data = raw_df.iloc[day_start_idx + t]
        high = current_minute_raw_data['high']
        low = current_minute_raw_data['low']
        close = current_minute_raw_data['close']
        actual_volume = current_minute_raw_data['volume']

        # ã€å…³é”®ä¿®æ­£ã€‘å®šä¹‰æœ¬åˆ†é’Ÿçš„æˆäº¤ä»·æ ¼
        execution_price = (high + low + close) / 3.0

        remaining_quantity -= final_order_quantity

        results_log.append({
            'timestamp': current_minute_raw_data['date'],
            'logic_used': logic_used,
            'execution_price': execution_price,  # ä½¿ç”¨ä¿®æ­£åçš„ä»·æ ¼
            'actual_volume': actual_volume,
            'order_quantity': final_order_quantity,
            'trade_value': final_order_quantity * execution_price,  # ä½¿ç”¨ä¿®æ­£åçš„ä»·æ ¼
            'remaining_quantity': remaining_quantity
        })

    # --- åå¤„ç†ä¸æŒ‡æ ‡è®¡ç®— ---
    results_df = pd.DataFrame(results_log)
    if results_df.empty or results_df['order_quantity'].sum() < 1e-6:
        return pd.DataFrame(), {}

    # ã€å…³é”®ä¿®æ­£ã€‘åŸºå‡†VWAPçš„è®¡ç®—ä¹Ÿä½¿ç”¨ç»Ÿä¸€çš„æˆäº¤ä»·æ ‡å‡† (execution_price)
    total_actual_value_for_benchmark = (results_df['execution_price'] * results_df['actual_volume']).sum()
    total_actual_volume_for_benchmark = results_df['actual_volume'].sum()
    benchmark_vwap = total_actual_value_for_benchmark / total_actual_volume_for_benchmark if total_actual_volume_for_benchmark > 0 else 0

    model_total_trade_value = results_df['trade_value'].sum()
    model_total_quantity_traded = results_df['order_quantity'].sum()
    model_achieved_price = model_total_trade_value / model_total_quantity_traded if model_total_quantity_traded > 0 else 0

    if trade_direction == 'Buy':
        slippage_per_share = benchmark_vwap - model_achieved_price
    else:  # Sell
        slippage_per_share = model_achieved_price - benchmark_vwap

    total_cost_savings = slippage_per_share * total_quantity
    slippage_bps = (slippage_per_share / benchmark_vwap) * 10000 if benchmark_vwap > 0 else 0

    # è®¡ç®—ç»˜å›¾æ›²çº¿
    results_df['cumulative_benchmark_value'] = (results_df['execution_price'] * results_df['actual_volume']).cumsum()
    results_df['cumulative_actual_volume'] = results_df['actual_volume'].cumsum()
    results_df['traditional_vwap_line'] = results_df['cumulative_benchmark_value'] / results_df[
        'cumulative_actual_volume']

    results_df['cumulative_model_value'] = results_df['trade_value'].cumsum()
    results_df['cumulative_model_volume'] = results_df['order_quantity'].cumsum()
    results_df['model_vwap_line'] = (
                results_df['cumulative_model_value'] / results_df['cumulative_model_volume']).replace([np.inf, -np.inf],
                                                                                                      np.nan).ffill()

    metrics = {"Benchmark VWAP": benchmark_vwap, "Model Achieved Price": model_achieved_price,
               "Slippage Reduction (BPS)": slippage_bps, "Total Cost Savings": total_cost_savings}

    return results_df.set_index('timestamp'), metrics


# --- Streamlit UI ---
st.set_page_config(layout="wide")
st.title("åŠ¨æ€è‡ªé€‚åº”VWAPç­–ç•¥å›æµ‹å¹³å° (V3 - ä»·æ ¼ä¿®æ­£ç‰ˆ)")

st.info("""
**V3 æ›´æ–°:** ä¿®æ­£äº†æ ¸å¿ƒçš„ä»·æ ¼è®¡ç®—é€»è¾‘ã€‚
- **æˆäº¤ä»·æ ¼:** æ¯åˆ†é’Ÿçš„æˆäº¤ä»·ä¸å†ä½¿ç”¨æ¨¡å‹å†…éƒ¨çš„æ ‡å‡†åŒ–æ•°æ®ï¼Œè€Œæ˜¯ä¸¥æ ¼é‡‡ç”¨åŸå§‹æ•°æ®ä¸­çš„ **(æœ€é«˜ä»· + æœ€ä½ä»· + æ”¶ç›˜ä»·) / 3**ã€‚
- **å…¬å¹³åŸºå‡†:** ç”¨äºè®¡ç®—åŸºå‡†VWAPçš„ä»·æ ¼ä¹Ÿé‡‡ç”¨ä¸Šè¿°åŒæ ·æ ‡å‡†ï¼Œç¡®ä¿äº†ç­–ç•¥ä¸åŸºå‡†ä¹‹é—´çš„å¯¹æ¯”æ˜¯å…¬å¹³çš„ã€‚
""")

# ... ä¾§è¾¹æ UIéƒ¨åˆ†ä¸ä¸Šä¸€ç‰ˆå®Œå…¨ç›¸åŒ ...
with st.sidebar:
    st.header("âš™ï¸ æ¨¡å‹ä¸æ•°æ®è®¾ç½®")
    data_file = st.text_input("åŒ…å«OHLCVå’Œç‰¹å¾çš„å®Œæ•´å†å²æ•°æ®CSVè·¯å¾„", 'data/latent_features/c9999_1min_data.csv')
    st.subheader("æ¨¡å‹è·¯å¾„")
    vae_model_path = st.text_input("VAE Model Path", 'best_tdist_vae_model.pth')
    predictor_model_path = st.text_input("Predictor Model Path", 'best_GPTpredictor_model.pth')

    st.subheader("å›æµ‹å‚æ•°")
    selected_date_str = st.selectbox("é€‰æ‹©åˆ†ææ—¥æœŸ", options=[])
    trade_direction = st.selectbox("äº¤æ˜“æ–¹å‘", options=['Buy', 'Sell'])
    total_quantity = st.number_input("æ€»äº¤æ˜“æ•°é‡", min_value=1, value=10000, step=100)

    st.subheader("æ”¶ç›˜å†²åˆºå‚æ•°")
    failsafe_ratio = st.slider("ç­‰æ¯”çº§æ•°å…¬æ¯” (r)", 0.1, 1.0, 0.75, 0.05,
                               help="æ§åˆ¶æœ€å5åˆ†é’Ÿä¸‹å•é€Ÿåº¦ã€‚rè¶Šå°ï¼Œä¸‹å•é‡é€’å‡è¶Šå¿«ã€‚")

    st.subheader("æ¨¡å‹è¶…å‚æ•°")
    seq_length = st.number_input("Sequence Length", value=345)
    latent_dim = st.number_input("VAE Latent Dimension", value=16)
    ohlcv_dim = st.number_input("OHLCV Dimension", value=6)

    run_button = st.button("ğŸš€ è¿è¡Œåˆ†æ", type="primary", use_container_width=True)

# --- ä¸»åº”ç”¨é€»è¾‘ ---
if data_file:
    # åŠ¨æ€æ›´æ–°æ—¥æœŸé€‰æ‹©å™¨
    # ä½¿ç”¨  (temporary) DataFrame æ¥é¿å…é‡å¤åŠ è½½å®Œæ•´æ•°æ®
    temp_df = pd.read_csv(data_file, usecols=['date'])
    unique_dates = sorted(pd.to_datetime(temp_df['date']).dt.date.unique(), reverse=True)
    st.sidebar.selectbox("é€‰æ‹©åˆ†ææ—¥æœŸ", options=unique_dates, key='selected_date_str')

if run_button and data_file:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    st.write(f"Using device: `{device}`")

    try:
        # ã€å…³é”®ä¿®æ­£ã€‘åŠ è½½ä¸¤ä»½æ•°æ®ï¼šä¸€ä»½ç»™æ¨¡å‹ç”¨ï¼Œä¸€ä»½ä¸ºåŸå§‹æ•°æ®ç”¨äºå›æµ‹
        with st.spinner("åŠ è½½æ•°æ®å’Œæ¨¡å‹ä¸­..."):
            # seek(0) ç¡®ä¿æ¯æ¬¡éƒ½èƒ½ä»æ–‡ä»¶å¼€å¤´è¯»å–
            raw_df = pd.read_csv(data_file, parse_dates=['date'])
            dataset = load_financial_data(raw_df, data_file, seq_length, latent_dim)

            vae_model = load_vae_model(vae_model_path, ohlcv_dim, latent_dim, 64, 5.0, device)
            predictor_model = load_predictor_model(predictor_model_path, latent_dim, ohlcv_dim, seq_length, device)

        # æ‰¾åˆ°æ—¥æœŸçš„èµ·å§‹ç´¢å¼•
        selected_date = pd.to_datetime(st.session_state.selected_date_str).date()
        # æˆ‘ä»¬éœ€è¦ä»åŸå§‹æ•°æ®ä¸­å®šä½ï¼Œå› ä¸ºdataset.dateså¯èƒ½æ ¼å¼ä¸åŒ
        day_start_offset = raw_df.index[raw_df['date'].dt.date == selected_date]

        if len(day_start_offset) < seq_length:
            st.error(f"æ—¥æœŸ {selected_date} çš„æ•°æ®ä¸è¶³ (éœ€è¦ {seq_length} åˆ†é’Ÿ, æ‰¾åˆ° {len(day_start_offset)} åˆ†é’Ÿ)ã€‚")
            st.stop()
        day_start_idx = day_start_offset[0]

        # è°ƒç”¨æ–°çš„æ ¸å¿ƒå›æµ‹å‡½æ•°ï¼Œå¹¶ä¼ å…¥åŸå§‹æ•°æ® raw_df
        results_df, metrics = run_adaptive_backtest(
            predictor_model, dataset, raw_df, day_start_idx, seq_length,
            total_quantity, trade_direction, failsafe_ratio, device
        )

        st.header(f"ğŸ“Š åŠ¨æ€è‡ªé€‚åº”ç­–ç•¥å›æµ‹ç»“æœ: {selected_date}")
        if not metrics:
            st.warning("æœªèƒ½è®¡ç®—å›æµ‹æŒ‡æ ‡ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ²¡æœ‰å‘ç”Ÿä»»ä½•äº¤æ˜“ã€‚")
        else:
            # æŒ‡æ ‡å±•ç¤º
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("åŸºå‡†VWAP", f"${metrics['Benchmark VWAP']:.4f}")
            col2.metric("æ¨¡å‹å®ç°å‡ä»·", f"${metrics['Model Achieved Price']:.4f}")
            col3.metric("BPSæ»‘ç‚¹èŠ‚çœ", f"{metrics['Slippage Reduction (BPS)']:.2f} bps")
            col4.metric("æ€»æˆæœ¬èŠ‚çœ", f"${metrics['Total Cost Savings']:,.2f}")

        st.header("ğŸ’° VWAP è¡¨ç°å›¾")
        # ç»˜å›¾...
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=results_df.index, y=results_df['traditional_vwap_line'], name='åŸºå‡† VWAP (HLC/3)',
                                 line=dict(color='royalblue', width=3)))
        fig.add_trace(go.Scatter(x=results_df.index, y=results_df['model_vwap_line'], name='æ¨¡å‹è‡ªé€‚åº”VWAP',
                                 line=dict(color='red', width=2, dash='dash')))
        fig.update_layout(hovermode="x unified")
        st.plotly_chart(fig, use_container_width=True)

        st.header("ğŸ“‹ åˆ†é’Ÿçº§äº¤æ˜“æ—¥å¿—")
        # è¯¦ç»†æ—¥å¿—å±•ç¤º...
        display_cols = ['logic_used', 'execution_price', 'order_quantity', 'trade_value', 'remaining_quantity']
        st.dataframe(results_df[display_cols].style.format(precision=2))

    except FileNotFoundError as e:
        st.error(f"æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {e}. è¯·æ£€æŸ¥ä¾§è¾¹æ ä¸­çš„è·¯å¾„ã€‚")
    except Exception as e:
        st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
        import traceback

        st.code(traceback.format_exc())

elif run_button:
    st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ‚¨çš„å†å²æ•°æ®CSVæ–‡ä»¶ã€‚")