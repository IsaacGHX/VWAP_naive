import os
import pandas as pd


def consolidate_futures_data(root_dir, target_symbol, output_dir, output_file):
    """
    éå†æŒ‡å®šçš„ç›®å½•ç»“æ„ï¼Œä¸ºç›®æ ‡åˆçº¦ç”Ÿæˆä¸€ä¸ªåˆå¹¶çš„CSVæ–‡ä»¶ã€‚

    :param root_dir: åŒ…å«YYYYMMæ–‡ä»¶å¤¹çš„æ ¹ç›®å½•ã€‚
    :param target_symbol: éœ€è¦æŠ½å–çš„åˆçº¦ä»£ç ï¼Œä¾‹å¦‚ 'IF9999'ã€‚
    :param output_file: è¾“å‡ºçš„CSVæ–‡ä»¶åã€‚
    """
    print(f"ğŸš€ å¼€å§‹å¤„ç†æ•°æ®ï¼Œç›®æ ‡åˆçº¦: {target_symbol}")
    print(f"ğŸ“‚ æ‰«ææ ¹ç›®å½•: {os.path.abspath(root_dir)}")

    all_symbol_data = []
    processed_files = 0

    # ä½¿ç”¨os.walkéå†æ‰€æœ‰å­ç›®å½•å’Œæ–‡ä»¶
    for dirpath, _, filenames in os.walk(root_dir):
        for filename in filenames:
            if filename.endswith('.csv'):
                file_path = os.path.join(dirpath, filename)
                try:
                    # è¯»å–CSVæ–‡ä»¶åˆ°DataFrame
                    daily_df = pd.read_csv(file_path)
                    processed_files += 1

                    # ç­›é€‰å‡ºç›®æ ‡åˆçº¦çš„æ•°æ®
                    symbol_df = daily_df[daily_df['symbol'] == target_symbol]

                    # å¦‚æœæ‰¾åˆ°äº†æ•°æ®ï¼Œå°±å°†å…¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    if not symbol_df.empty:
                        all_symbol_data.append(symbol_df)

                except Exception as e:
                    print(f"âš ï¸ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ {file_path}: {e}")

    if not all_symbol_data:
        print(f"âŒ æœªåœ¨ {processed_files} ä¸ªæ–‡ä»¶ä¸­æ‰¾åˆ°åˆçº¦ '{target_symbol}' çš„ä»»ä½•æ•°æ®ã€‚")
        return

    print(f"âœ… åœ¨ {processed_files} ä¸ªæ–‡ä»¶ä¸­ï¼Œæ‰¾åˆ°äº† {len(all_symbol_data)} æ¡å…³äº '{target_symbol}' çš„è®°å½•ã€‚")

    # å°†æ‰€æœ‰æ‰¾åˆ°çš„DataFrameåˆå¹¶æˆä¸€ä¸ª
    final_df = pd.concat(all_symbol_data, ignore_index=True)

    # --- æ•°æ®æ ¼å¼åŒ– ---

    # 1. å®šä¹‰éœ€è¦ä¿ç•™çš„åŸå§‹åˆ—åå’Œæ–°çš„å°å†™åˆ—å
    columns_map = {
        'eob': 'date',
        'open': 'open',
        'close': 'close',
        'high': 'high',
        'low': 'low',
        'volume': 'volume',
        'amount': 'amount',
        'position': 'position'
    }

    # 2. åªä¿ç•™éœ€è¦çš„åˆ—ï¼Œå¹¶é‡å‘½å
    final_df = final_df[columns_map.keys()].rename(columns=columns_map)

    # 3. æŒ‰ç…§æ—¥æœŸæ’åºï¼Œç¡®ä¿æ•°æ®æ˜¯æ—¶åºæ­£ç¡®çš„
    final_df = final_df.sort_values(by='date', ascending=True)

    # 4. (å¯é€‰) è°ƒæ•´åˆ—çš„é¡ºåºï¼Œæ›´ç¬¦åˆä¹ æƒ¯
    column_order = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'position']
    final_df = final_df[column_order]

    # --- ä¿å­˜æ–‡ä»¶ ---
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, output_file)
    final_df.to_csv(output_file, index=False)
    print(f"ğŸ‰ æˆåŠŸï¼æ•°æ®å·²ä¿å­˜è‡³: {output_file}")
    print(f"æ€»è®¡ {len(final_df)} è¡Œæ•°æ®ã€‚")


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":

    # --- æ‚¨éœ€è¦ä¿®æ”¹çš„é…ç½® ---

    # 1. æ•°æ®æ‰€åœ¨çš„æ ¹ç›®å½• (å¦‚æœè„šæœ¬å’Œ202201ç­‰æ–‡ä»¶å¤¹åœ¨åŒä¸€çº§ï¼Œä¿æŒ'.'å³å¯)
    ROOT_DATA_DIR = r'D:\Desktop\SHU\Intern\åŒæ¢AIé‡åŒ–\database\1day\output'

    # 2. æ‚¨æƒ³è¦æŠ½å–çš„åˆçº¦ä»£ç 
    TARGET_SYMBOL = 'c9999'

    OUTPUT_DIR = "./data/raw_data"
    # 3. è¾“å‡ºæ–‡ä»¶çš„åç§°
    OUTPUT_FILENAME = f'{TARGET_SYMBOL}_daily_data.csv'

    # --- æ‰§è¡Œå‡½æ•° ---
    consolidate_futures_data(
        root_dir=ROOT_DATA_DIR,
        target_symbol=TARGET_SYMBOL,
        output_dir=OUTPUT_DIR,
        output_file=OUTPUT_FILENAME
    )